{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.environ.get(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorstore.pkl\", \"rb\") as f:\n",
    "    vectorstore = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "Agents use an LLM to determine which actions to perform and in what order. An action can be either using a tool and observing its output or returning it to the user. To use an agent, in addition to the concept of an LLm, it is important to understand a new concept and that of a \"tool\"\n",
    "\n",
    "\n",
    "Agent makes use of ReACt framework. ReAct = Reasoning + Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "Tools are functions that agents can use to interact with the world. These tools can be common utilities (e.g. search), other chains, or even other agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name = \"gpt-4\", temperature = 0.7)\n",
    "\n",
    "tool_names = [\"llm-math\"]\n",
    "tools = load_tools(tool_names, llm = llm)\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "tool_list = [\n",
    "    Tool(\n",
    "        name = \"Math Tool\",\n",
    "        func = tools[0].run,\n",
    "        description= \"tool to calculate, nothing else\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tool_list,\n",
    "    llm,\n",
    "    agent = \"zero-shot-react-description\",\n",
    "    verbose = True)\n",
    "agent.run(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"what is 100 devided by 25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should write our custom tools that retrive information from our vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Tool\n",
    "\n",
    "You can also create your own tools by creatig a class that inherits from BaseTool class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "\n",
    "# our class is inherited from BaseTool class\n",
    "class CustomSearchTool(BaseTool):\n",
    "    name = \"restaurant search\"\n",
    "    description = \"useful for when you need to answer questions about our restaurant\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        # we have create retriever for query\n",
    "        store = vectorstore.as_retriever()\n",
    "        # use retriever to get relevant documents and pass in the query (this will be embedded and we will get back the most similar documents from the document store and this will be list of documents)\n",
    "        docs = store.get_relevant_documents(query)\n",
    "        # we can extract page content from document class\n",
    "        text_list = [doc.page_content for doc in docs]\n",
    "        return \"\\n\".join(text_list)\n",
    "    \n",
    "    \n",
    "    # for asynchronous tasks\n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        # Use the tool asynchronously\n",
    "        raise NotImplementedError(\"custom search does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "\n",
    "# tool name is the class name that we defined\n",
    "tools = [CustomSearchTool()]\n",
    "\n",
    "# pass this as a tool list to our initialize agent function\n",
    "agent = initialize_agent(tools,llm, agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"when does the restaurant open?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
